\documentclass[10pt,twocolumn]{article}
\usepackage[margin=2cm]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{float}
\usepackage{graphicx,booktabs,multirow,caption}
\usepackage{stfloats} % o \usepackage{dblfloatfix}
\begin{document}

\section*{Análisis Comparativo de Algoritmos Evolutivos}

En este apartado se presentan los resultados obtenidos al evaluar diferentes algoritmos (Firefly, ACOR, Algoritmo Genético Diploide y PSO con división de población) sobre un conjunto de benchmarks dinámicos. Los resultados se analizaron considerando cuatro dimensiones principales: \textbf{calidad}, \textbf{robustez}, \textbf{adaptabilidad} y \textbf{coste computacional}.

\subsection*{Métricas de Evaluación}

Para caracterizar el desempeño de los algoritmos se utilizaron las siguientes métricas, seleccionadas por su relevancia en la comparación de métodos metaheurísticos en entornos dinámicos:

\begin{itemize}
    \item \textbf{Calidad}: medida a través de los valores \textit{Avg Best Pre-Change}, \textit{Avg Avg Pre-Change} y \textit{Avg Worst Pre-Change}. 
    Estas métricas permiten observar el rango de soluciones alcanzadas (mejor, promedio y peor caso), ofreciendo una visión integral del nivel de desempeño que un algoritmo puede garantizar antes de que ocurra un cambio en el entorno.
    
    \item \textbf{Robustez}: evaluada mediante la desviación estándar \textit{Avg Std Pre-Change}. 
    Una baja desviación estándar refleja que el algoritmo produce resultados consistentes entre diferentes ejecuciones, lo que es esencial en problemas donde la estabilidad es tan importante como la calidad.
    
    \item \textbf{Adaptabilidad}: cuantificada mediante las iteraciones promedio de recuperación \textit{Avg Recovery Iter}. 
    Esta métrica mide la rapidez con la que el algoritmo puede reajustarse tras un cambio en el entorno, capturando su capacidad de adaptación en escenarios dinámicos.
    
    \item \textbf{Coste}: representado por el tiempo promedio de ejecución en segundos (\textit{Avg Time (s)}). 
    Esta medida asegura que la comparación no solo contemple la calidad y adaptabilidad de las soluciones, sino también la eficiencia computacional, aspecto clave en aplicaciones prácticas donde los recursos de tiempo y cómputo son limitados.
\end{itemize}
\subsection*{Resultados}

A continuación se muestra un extracto de los resultados obtenidos para cada algoritmo. 

% --- FIREfly ---
\begin{table}[H]
\centering
\caption{Firefly (30\% reubicación de población): resultados promedios por benchmark.}
\label{tab:firefly}
\scriptsize
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\textbf{Algoritmo} & \textbf{Benchmark} & \textbf{Best} & \textbf{Avg} & \textbf{Worst} & \textbf{Std} & \textbf{Recov. Iter} & \textbf{Time (s)} \\
\midrule
Firefly & 1 & 4.33 & 4.65 & 4.94 & 0.30 & 6 & 21.70 \\
Firefly & 2 & 0.00 & 0.00 & 0.01 & 0.00 & 2 & 142.55 \\
Firefly & 3 & 1.95 & 10.80 & 19.56 & 7.10 & 7 & 44.18 \\
Firefly & 4 & 0.01 & 0.35 & 1.57 & 0.53 & 3 & 8.69 \\
Firefly & 5 & -307.25 & -210.96 & -124.78 & 56.98 & 9 & 16.24 \\
\bottomrule
\end{tabular}}
\end{table}

\subsubsection*{Firefly (30\% reubicación de población)}
\textbf{Resumen global.} Desempeño aceptable en \textit{B1} y \textit{B4}; inestable en \textit{B3} y especialmente sensible en \textit{B5}. Coste moderado salvo en \textit{B2}. \\
\textbf{B1:} Calidad media (Best=4.33, Avg=4.65) con variabilidad moderada (Std=0.30); adaptabilidad intermedia (Rec=6) y tiempo razonable (21.7 s). \\
\textbf{B2:} Problema “fácil” para el método (valores $\approx 0$) y buena adaptabilidad (Rec=2), pero \textbf{muy costoso} (142.6 s), lo que sugiere sobrecosto computacional. \\
\textbf{B3:} Calidad pobre (Avg=10.80) y \textbf{alta variabilidad} (Std=7.10); recuperación lenta (Rec=7) $\rightarrow$ poca robustez ante cambios. \\
\textbf{B4:} Calidad aceptable (Avg=0.35) con dispersión notable (Std=0.53); recuperación rápida (Rec=3) y \textbf{bajo coste} (8.69 s). \\
\textbf{B5:} Valores muy negativos (Avg=-210.96) con \textbf{gran dispersión} (Std=56.98) y la peor adaptabilidad (Rec=9); tiempo razonable (16.24 s). \\
\textbf{Lectura:} Firefly es competitivo cuando la estructura del problema favorece la exploración guiada (\textit{B1}, \textit{B4}); en escenarios con paisajes complejos/dinámicos (\textit{B3}, \textit{B5}) pierde estabilidad y tarda en recuperarse. \textbf{Cuello de botella:} \textit{B2} por tiempo.


% --- ACOR ---
\begin{table}[H]
\centering
\caption{ACOR (15\% reubicación de población): resultados promedios por benchmark.}
\label{tab:acor}
\scriptsize
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\textbf{Algoritmo} & \textbf{Benchmark} & \textbf{Best} & \textbf{Avg} & \textbf{Worst} & \textbf{Std} & \textbf{Recov. Iter} & \textbf{Time (s)} \\
\midrule
ACOR & 1 & 4.32 & 4.64 & 4.94 & 0.32 & 4 & 21.43 \\
ACOR & 2 & 0.00 & 0.00 & 0.00 & 0.00 & 2 & 229.78 \\
ACOR & 3 & 0.62 & 7.75 & 16.02 & 6.29 & 5 & 45.06 \\
ACOR & 4 & 0.21 & 1.37 & 4.14 & 1.24 & 4 & 8.21 \\
ACOR & 5 & -372.73 & -283.08 & -196.89 & 56.53 & 12 & 16.47 \\
\bottomrule
\end{tabular}}
\end{table}

\subsubsection*{ACOR (15\% reubicación para soluciones cercanas)}
\textbf{Resumen global.} Rendimiento intermedio: mejor que Firefly en \textit{B3} (promedio menor) pero con costes más altos, y \textbf{muy sensible} en \textit{B5} (recupera lento). \\
\textbf{B1:} Calidad similar a Firefly (Avg=4.64), variabilidad mayor (Std=0.32), recuperación algo mejor (Rec=4), coste parecido (21.4 s). \\
\textbf{B2:} Excelente calidad ($\approx 0$) y buena adaptabilidad (Rec=2), pero \textbf{el más costoso} (229.8 s). \\
\textbf{B3:} Mejora frente a Firefly (Avg=7.75 vs 10.80) aunque \textbf{aún inestable} (Std=6.29); adaptabilidad intermedia (Rec=5); tiempo similar (45.1 s). \\
\textbf{B4:} Calidad moderada (Avg=1.37) con alta variabilidad (Std=1.24); recuperación intermedia (Rec=4); coste bajo (8.21 s). \\
\textbf{B5:} Muy negativo en calidad (Avg=-283.08) con \textbf{gran dispersión} (Std=56.53) y \textbf{la peor recuperación del grupo} (Rec=12); coste bajo (16.47 s). \\
\textbf{Lectura:} ACOR tiende a \textbf{sobre‐gastar tiempo} para alcanzar precisión en problemas “fáciles” (\textit{B2}) y su \textbf{debilidad principal} está en adaptabilidad ante cambios severos (\textit{B5}).


% --- Genético Diploide ---
\begin{table}[H]
\centering
\caption{Algoritmo Genético Diploide: resultados promedios por benchmark.}
\label{tab:ga-diploide}
\scriptsize
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\textbf{Algoritmo} & \textbf{Benchmark} & \textbf{Best} & \textbf{Avg} & \textbf{Worst} & \textbf{Std} & \textbf{Recov. Iter} & \textbf{Time (s)} \\
\midrule
Gen. Diploide & 1 & 0.00 & 0.04 & 0.36 & 0.11 & 1 & 23.20 \\
Gen. Diploide & 2 & 0.00 & 0.00 & 0.00 & 0.00 & 1 & 261.86 \\
Gen. Diploide & 3 & 0.12 & 0.12 & 0.13 & 0.00 & 1 & 46.44 \\
Gen. Diploide & 4 & 0.05 & 0.06 & 0.08 & 0.01 & 1 & 10.12 \\
Gen. Diploide & 5 & -365.08 & -336.99 & -241.26 & 42.51 & 3 & 17.90 \\
\bottomrule
\end{tabular}}
\end{table}

\subsubsection*{Algoritmo Genético Diploide}
\textbf{Resumen global.} \textbf{Mejor calidad y robustez} de los cuatro: promedios cercanos al óptimo y \textbf{desviaciones muy bajas}. Adaptabilidad \textbf{excelente} (Rec=1 en 4/5 benchmarks), pero con \textbf{coste elevado} en \textit{B2}. \\
\textbf{B1:} Calidad casi óptima (Avg=0.036) y \textbf{baja variabilidad} (Std=0.113); recuperación inmediata (Rec=1); coste moderado (23.2 s). \\
\textbf{B2:} Calidad perfecta ($\approx 0$), recuperación inmediata (Rec=1), pero \textbf{muy costoso} (261.9 s), el mayor tiempo de todos. \\
\textbf{B3:} \textbf{Excelente} (Avg=0.121, Std=0.0039): prácticamente \textbf{determinista}; Rec=1; tiempo moderado (46.4 s). \\
\textbf{B4:} Muy bueno (Avg=0.063, Std=0.012); Rec=1; coste bajo (10.1 s). \\
\textbf{B5:} Calidad muy competitiva (Avg=-336.99) y mejor que ACOR/Firefly/PSO; variabilidad elevada (Std=42.51) y Rec=3; coste moderado (17.9 s). \\
\textbf{Lectura:} Es la opción \textbf{más fiable} y \textbf{rápida en recuperarse} tras cambios. El precio a pagar es el \textbf{tiempo} en \textit{B2}. Ideal cuando se prioriza precisión/estabilidad sobre coste.


% --- PSO dividido ---
\begin{table}[H]
\centering
\caption{PSO dividido (population split): resultados promedios por benchmark.}
\label{tab:pso-dividido}
\scriptsize
\resizebox{\columnwidth}{!}{%
\begin{tabular}{lccccccc}
\toprule
\textbf{Algoritmo} & \textbf{Benchmark} & \textbf{Best} & \textbf{Avg} & \textbf{Worst} & \textbf{Std} & \textbf{Recov. Iter} & \textbf{Time (s)} \\
\midrule
PSO dividido & 1 & 5.94 & 7.39 & 10.01 & 1.28 & 3 & 20.98 \\
PSO dividido & 2 & 0.00 & 0.01 & 0.07 & 0.02 & 4 & 203.13 \\
PSO dividido & 3 & 3.45 & 11.69 & 18.89 & 5.93 & 8 & 44.62 \\
PSO dividido & 4 & 0.68 & 2.35 & 5.22 & 1.39 & 4 & 8.37 \\
PSO dividido & 5 & -325.05 & -231.30 & -152.20 & 54.13 & 7 & 16.34 \\
\bottomrule
\end{tabular}}
\end{table}

\subsubsection*{PSO con división de población}
\textbf{Resumen global.} \textbf{El menos competitivo} en calidad media y robustez; adaptabilidad irregular (Rec alto en \textit{B3}, \textit{B5}); costes moderados salvo \textit{B2}. \\
\textbf{B1:} Peor calidad (Avg=7.39) y variabilidad alta (Std=1.28); adaptabilidad intermedia (Rec=3); coste moderado (21.0 s). \\
\textbf{B2:} Calidad aceptable ($\approx 0.014$) pero recuperación peor que Firefly/ACOR/GA (Rec=4); \textbf{coste alto} (203.1 s). \\
\textbf{B3:} \textbf{Muy inestable} (Avg=11.69, Std=5.93) y lenta recuperación (Rec=8); tiempo similar a los demás (44.6 s). \\
\textbf{B4:} Calidad moderada (Avg=2.35) con alta variabilidad (Std=1.39); Rec=4; coste bajo (8.37 s). \\
\textbf{B5:} Calidad inferior al GA (Avg=-231.30) y \textbf{alta dispersión} (Std=54.13); recuperación lenta (Rec=7); coste bajo (16.34 s). \\
\textbf{Lectura:} La división de población aporta diversidad, pero \textbf{no se traduce en robustez} post‐cambio ni en calidad media; requiere \textbf{mejoras de explotación} y mecanismos de recuperación.


\subsection*{Discusión Comparativa}
En términos de \textbf{calidad y robustez}, el Algoritmo Genético Diploide domina al presentar los promedios más bajos y desviaciones estándar mínimas. Esto lo convierte en el método más preciso y estable. En comparación, ACOR y Firefly logran desempeños intermedios que dependen del benchmark, mientras que PSO dividido queda rezagado al mostrar soluciones de menor calidad y una mayor variabilidad en sus resultados.  

Respecto a la \textbf{adaptabilidad}, el Algoritmo Genético Diploide vuelve a sobresalir, ya que en casi todos los casos logra recuperarse en una sola iteración. Le siguen ACOR y Firefly, con tiempos de recuperación intermedios, mientras que PSO dividido resulta claramente más lento en escenarios dinámicos como los benchmarks B3 y B5.  

En cuanto al \textbf{coste computacional}, el Genético Diploide muestra un punto débil, pues en el Benchmark 2 resulta considerablemente más costoso en términos de tiempo. ACOR también incrementa su coste en ciertos escenarios, mientras que Firefly y PSO suelen ser más eficientes, con tiempos de ejecución menores, salvo en el caso particular del Benchmark 2.

Por otro lado, de los algoritmos evaluados, el \textbf{PSO con división de población} mostró el peor desempeño general en términos de las métricas consideradas. En primer lugar, la \textbf{calidad de las soluciones} obtenidas fue inferior respecto a los demás algoritmos, ya que en múltiples benchmarks los valores promedio fueron considerablemente más altos. Esto refleja que, aunque la división de la población favorece la diversidad, el mecanismo de explotación no logra refinar adecuadamente las soluciones.

En segundo lugar, la \textbf{robustez} del método resultó limitada. Las desviaciones estándar reportadas fueron elevadas, lo que indica una fuerte variabilidad entre ejecuciones. En consecuencia, el algoritmo se percibe como poco confiable, pues bajo las mismas condiciones iniciales puede producir resultados muy distintos.

Otro aspecto crítico fue la \textbf{adaptabilidad}. El PSO dividido requirió más iteraciones de recuperación en escenarios dinámicos, especialmente en benchmarks donde los cambios eran más severos. En términos prácticos, esto significa que tarda demasiado en reajustarse después de un cambio, perdiendo competitividad frente a los demás métodos.

Finalmente, en lo referente al \textbf{coste computacional}, aunque en algunos casos el tiempo de ejecución fue razonable, en problemas como el Benchmark 2 se registraron valores muy altos (más de 200 segundos), sin que ello se tradujera en una mejora en la calidad de las soluciones.

En conclusión, el \textbf{PSO con división de población} fue el peor algoritmo en esta evaluación porque combina una baja calidad promedio con alta variabilidad, recuperación lenta y costes computacionales elevados, lo que lo hace menos competitivo frente a Firefly, ACOR y, en particular, el Algoritmo Genético Diploide.



\subsection*{Conclusiones}

Los Algoritmos Genéticos Diploides son superiores en \textbf{calidad, robustez y adaptabilidad}, aunque con un coste elevado. Firefly es balanceado, ACOR intermedio y PSO rápido pero menos confiable.

\end{document}